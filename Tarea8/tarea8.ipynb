{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tensorflow.keras import layers, Model\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AJM</th>\n",
       "      <th>BJU</th>\n",
       "      <th>CAM</th>\n",
       "      <th>FAR</th>\n",
       "      <th>FECHA</th>\n",
       "      <th>HGM</th>\n",
       "      <th>HORA</th>\n",
       "      <th>INN</th>\n",
       "      <th>MER</th>\n",
       "      <th>MGH</th>\n",
       "      <th>MPA</th>\n",
       "      <th>PED</th>\n",
       "      <th>SAC</th>\n",
       "      <th>SAG</th>\n",
       "      <th>SFE</th>\n",
       "      <th>TLA</th>\n",
       "      <th>UIZ</th>\n",
       "      <th>XAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-99</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.45</td>\n",
       "      <td>-99</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.87</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.42</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-99</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.48</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.59</td>\n",
       "      <td>4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1.64</td>\n",
       "      <td>-99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.47</td>\n",
       "      <td>2.96</td>\n",
       "      <td>1.69</td>\n",
       "      <td>-99</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.12</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AJM   BJU   CAM   FAR      FECHA   HGM  HORA   INN   MER  MGH   MPA   PED  \\\n",
       "0  0.45  1.24  1.51  1.00 2023-01-01  0.80     1  0.20  1.71  1.2  0.15  0.46   \n",
       "1  0.43  1.53  1.66  1.49 2023-01-01  1.11     2  0.16  1.39  1.0  0.18  0.34   \n",
       "2  0.42  1.41  1.56  1.31 2023-01-01  1.49     3  0.13  1.14  1.2  0.17  0.40   \n",
       "3  0.48  1.14  1.43  1.11 2023-01-01  1.59     4  0.12  1.25  1.1  0.19  0.38   \n",
       "4  0.37  0.98  1.52  1.24 2023-01-01  1.06     5  0.11  1.38  1.3  0.16  0.47   \n",
       "\n",
       "    SAC   SAG  SFE   TLA   UIZ   XAL  \n",
       "0  0.45  1.70  -99  0.90  1.02 -99.0  \n",
       "1  0.68  1.45  -99  0.74  0.87 -99.0  \n",
       "2  1.94  1.46  -99  0.75  0.99 -99.0  \n",
       "3  2.46  1.64  -99  0.89  1.20 -99.0  \n",
       "4  2.96  1.69  -99  1.11  1.12 -99.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Find all .xls files in the folder\n",
    "folder = \"./23RAMA\"\n",
    "paths = glob.glob(os.path.join(folder, \"*.xls\"))\n",
    "\n",
    "# 2. Load each file into a DataFrame, store in a dict for easy reference\n",
    "dfs = {os.path.basename(p): pd.read_excel(p) for p in paths}\n",
    "\n",
    "# 3. Compute the intersection of columns across all DataFrames\n",
    "common_cols = set(dfs[next(iter(dfs))].columns)  # start with the first file’s columns\n",
    "for df in dfs.values():\n",
    "    common_cols &= set(df.columns)\n",
    "common_cols = sorted(common_cols)  # optional: sort alphabetically\n",
    "\n",
    "# 4. Filter each DataFrame to keep only the common columns\n",
    "for name, df in dfs.items():\n",
    "    dfs[name] = df.loc[:, common_cols]\n",
    "\n",
    "# Now `dfs` holds your cleaned DataFrames, keyed by filename.\n",
    "# Example: to access the cleaned DataFrame for 'file1.xls':\n",
    "cleaned_df = dfs[\"2023CO.xls\"]\n",
    "cleaned_df.head()  # Display the first few rows of the cleaned DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "long_tables = []\n",
    "\n",
    "for var_name, df in dfs.items():\n",
    "    # 1. Parse FECHA to datetime (dayfirst if your dates are dd/mm/YYYY)\n",
    "    df['FECHA'] = pd.to_datetime(df['FECHA'], dayfirst=True, errors='coerce')\n",
    "    \n",
    "    # 2. Convert HORA (int or str) into a timedelta of hours\n",
    "    df['HORA'] = pd.to_numeric(df['HORA'], errors='coerce').fillna(0).astype(int)\n",
    "    df['timestamp'] = df['FECHA'] + pd.to_timedelta(df['HORA'], unit='h')\n",
    "    \n",
    "    # 3. Melt each station column into rows\n",
    "    station_cols = [c for c in df.columns if c not in ('FECHA','HORA','timestamp')]\n",
    "    df_long = df.melt(\n",
    "        id_vars='timestamp',\n",
    "        value_vars=station_cols,\n",
    "        var_name='station',\n",
    "        value_name=var_name\n",
    "    )\n",
    "    \n",
    "    # 4. Keep just timestamp, station, and the variable\n",
    "    long_tables.append(df_long[['timestamp','station', var_name]])\n",
    "\n",
    "# 5. Inner-merge on (timestamp, station) across all variables\n",
    "big_df = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=['timestamp','station'], how='inner'),\n",
    "    long_tables\n",
    ")\n",
    "\n",
    "# 6. Extract feature matrix for your autoencoder\n",
    "X = big_df.drop(columns=['timestamp','station']).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 22:42:36.080385: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-04-29 22:42:36.080421: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-04-29 22:42:36.080424: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-04-29 22:42:36.080441: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-29 22:42:36.080452: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 22:42:36.621407: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - loss: 34.2521 - val_loss: 8.4340\n",
      "Epoch 2/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - loss: 305.5733 - val_loss: 935.5275\n",
      "Epoch 3/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 14ms/step - loss: 711.7605 - val_loss: 1254.3257\n",
      "Epoch 4/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 14ms/step - loss: 803.7786 - val_loss: 83.7353\n",
      "Epoch 5/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 1540.5088 - val_loss: 463.2620\n",
      "Epoch 6/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 1107.9438 - val_loss: 6.1162\n",
      "Epoch 7/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 3049.0862 - val_loss: 6290.9399\n",
      "Epoch 8/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 4212.8657 - val_loss: 4585.2329\n",
      "Epoch 9/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 15ms/step - loss: 4403.9790 - val_loss: 8.7838\n",
      "Epoch 10/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 14ms/step - loss: 2664.7202 - val_loss: 589.5716\n",
      "Epoch 11/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 14ms/step - loss: 4072.7078 - val_loss: 1.9878\n",
      "Epoch 12/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 3762.8198 - val_loss: 46.5059\n",
      "Epoch 13/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 5003.9302 - val_loss: 4.3972\n",
      "Epoch 14/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - loss: 4774.4688 - val_loss: 0.6834\n",
      "Epoch 15/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 2822.1726 - val_loss: 2.2336\n",
      "Epoch 16/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 5617.7544 - val_loss: 25516.8418\n",
      "Epoch 17/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 5980.9409 - val_loss: 147.1547\n",
      "Epoch 18/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - loss: 6114.7202 - val_loss: 13192.2656\n",
      "Epoch 19/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - loss: 20710.7969 - val_loss: 7.3086\n",
      "Epoch 20/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 7230.6431 - val_loss: 478.0978\n",
      "Epoch 21/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 11281.0488 - val_loss: 160553.9688\n",
      "Epoch 22/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 19781.3145 - val_loss: 38592.5547\n",
      "Epoch 23/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - loss: 16416.7637 - val_loss: 5.1192\n",
      "Epoch 24/100\n",
      "\u001b[1m2290/2290\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 14ms/step - loss: 20679.3711 - val_loss: 1.6260\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "n_features = X_scaled.shape[1]\n",
    "\n",
    "# Encoder\n",
    "inp = layers.Input(shape=(n_features,))\n",
    "h = layers.Dense(64, activation='relu')(inp)\n",
    "h = layers.Dense(32, activation='relu')(h)\n",
    "encoded = layers.Dense(2, activation=None, name='bottleneck')(h)\n",
    "\n",
    "# Decoder\n",
    "h = layers.Dense(32, activation='relu')(encoded)\n",
    "h = layers.Dense(64, activation='relu')(h)\n",
    "decoded = layers.Dense(n_features, activation=None)(h)\n",
    "\n",
    "# Full autoencoder\n",
    "autoencoder = Model(inp, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train\n",
    "history = autoencoder.fit(\n",
    "    X_scaled, X_scaled,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Extract the encoder model\n",
    "encoder = Model(inp, encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2544/2544\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'station'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'station'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 4c. Scatter-plot, color by station (or other grouping)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m station, group \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(codes2d, index\u001b[38;5;241m=\u001b[39m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mgroupby(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     12\u001b[0m     pts \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     13\u001b[0m     plt\u001b[38;5;241m.\u001b[39mscatter(pts[:, \u001b[38;5;241m0\u001b[39m], pts[:, \u001b[38;5;241m1\u001b[39m], label\u001b[38;5;241m=\u001b[39mstation, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'station'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 4a. Get 2D codes for each sample\n",
    "codes2d = encoder.predict(X_scaled)  # shape (n_samples, 2)\n",
    "\n",
    "# 4b. Recover station and timestamp labels\n",
    "labels = big_df.index.to_frame(index=False)  # DataFrame with columns ['timestamp', 'station']\n",
    "\n",
    "# 4c. Scatter-plot, color by station (or other grouping)\n",
    "plt.figure(figsize=(8, 6))\n",
    "for station, group in pd.DataFrame(codes2d, index=labels['station']).groupby(level=0):\n",
    "    pts = group.values\n",
    "    plt.scatter(pts[:, 0], pts[:, 1], label=station, s=10)\n",
    "\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.title('Autoencoder embedding of climate data')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), fontsize='small')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
